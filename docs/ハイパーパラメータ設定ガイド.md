## 🎯 学習ハイパーパラメータ設定ガイド

### 📍 設定場所

#### 1. **メイン設定ファイル** (`config/config.yaml`)

学習に関する基本パラメータ：

```yaml
development:
  training:
    # 基本パラメータ
    batch_size: 32              # 学習時のバッチサイズ
    eval_batch_size: 32         # 評価時のバッチサイズ 
    epochs: 100                 # 学習エポック数
    max_epochs: 100             # anomalibエンジン用
    learning_rate: 0.001        # 学習率
    early_stopping_patience: 10  # 早期停止のパチエンス
    
    # データ設定
    num_workers: 4              # データローダーのワーカー数
    val_split_ratio: 0.2        # 検証データの分割比率
    
    # モデル設定
    model_name: "padim"         # padim, patchcore, fastflow
    
    # オプティマイザー設定
    optimizer: "adam"           # adam, sgd, adamw
    weight_decay: 1e-5          # 重み減衰
    
    # 学習率スケジューラー
    lr_scheduler: "cosine"      # cosine, step, exponential
    lr_step_size: 30           # ステップスケジューラー用
    lr_gamma: 0.1              # ステップ・指数スケジューラー用
    
    # GPU設定
    device: "auto"             # auto, cpu, cuda
    mixed_precision: false     # 混合精度学習
```

#### 2. **GUI設定** (`training_app/gui/main_window.py`)

実行時にGUIで以下のパラメータを調整可能：

- **モデルタイプ**: PaDiM, PatchCore, FastFlow
- **エポック数**: 学習の反復回数
- **バッチサイズ**: 一度に処理するサンプル数
- **学習率**: パラメータ更新の大きさ
- **デバイス**: auto, cpu, cuda
- **早期停止**: パフォーマンス改善が止まったら学習終了

#### 3. **プログラム設定** (`training_manager.py`)

内部的に使用される詳細パラメータ：

```python
# データセット設定
"train_batch_size": self.config.get('training.batch_size', 16)
"eval_batch_size": self.config.get('training.eval_batch_size', 16)  
"num_workers": self.config.get('training.num_workers', 4)
"val_split_ratio": self.config.get('training.val_split_ratio', 0.2)

# エンジン設定
max_epochs=self.config.get('training.max_epochs', 10)
accelerator="gpu" if device == "cuda" else "cpu"
precision="16-mixed" if mixed_precision else "32"
```

### 🔧 設定方法

#### **方法1: 設定ファイル編集**
```yaml
# config/config.yaml を直接編集
development:
  training:
    batch_size: 16        # メモリ不足なら小さく
    epochs: 50           # 時間短縮なら少なく
    learning_rate: 0.01  # 学習が遅いなら大きく
```

#### **方法2: GUIでリアルタイム調整**
1. 学習アプリを起動
2. 「モデル学習」タブを選択
3. 「学習設定」でパラメータ調整
4. 「学習開始」で実行

#### **方法3: 環境別設定**
- `development`: 開発・実験用（高性能設定）
- `production`: 本番環境用（安定性重視）
- `test`: テスト用（軽量設定）

### 🎛️ パラメータ調整のコツ

#### **メモリ不足の場合**
```yaml
batch_size: 8          # 32 → 8に削減
num_workers: 2         # 4 → 2に削減
```

#### **学習高速化**
```yaml
batch_size: 64         # 大きなバッチサイズ
num_workers: 8         # 多くのワーカー
mixed_precision: true  # 混合精度有効
device: "cuda"         # GPU使用
```

#### **高精度モデル**
```yaml
epochs: 200            # 長時間学習
learning_rate: 0.0001  # 小さな学習率
early_stopping_patience: 20  # 忍耐強く
```

### 📊 推奨設定

| 用途 | batch_size | epochs | learning_rate | device |
|------|------------|--------|---------------|--------|
| 開発・実験 | 16-32 | 50-100 | 0.001 | cuda |
| 本番品質 | 16-64 | 100-200 | 0.0005 | cuda |
| 軽量テスト | 8-16 | 10-20 | 0.01 | cpu |
| GPU最適化 | 64-128 | 100+ | 0.001 | cuda |

### 🔍 設定の確認

現在の設定を確認：
```python
from training_app.core.training_manager import TrainingManager
tm = TrainingManager()
print(f"バッチサイズ: {tm.config.get('training.batch_size')}")
print(f"エポック数: {tm.config.get('training.epochs')}")
print(f"学習率: {tm.config.get('training.learning_rate')}")
```

これらの設定により、様々なハードウェア環境や学習要件に柔軟に対応できます。