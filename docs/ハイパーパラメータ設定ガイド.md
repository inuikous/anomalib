## ğŸ¯ å­¦ç¿’ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚¬ã‚¤ãƒ‰

### ğŸ“ è¨­å®šå ´æ‰€

#### 1. **ãƒ¡ã‚¤ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«** (`config/config.yaml`)

å­¦ç¿’ã«é–¢ã™ã‚‹åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š

```yaml
development:
  training:
    # åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    batch_size: 32              # å­¦ç¿’æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
    eval_batch_size: 32         # è©•ä¾¡æ™‚ã®ãƒãƒƒãƒã‚µã‚¤ã‚º 
    epochs: 100                 # å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°
    max_epochs: 100             # anomalibã‚¨ãƒ³ã‚¸ãƒ³ç”¨
    learning_rate: 0.001        # å­¦ç¿’ç‡
    early_stopping_patience: 10  # æ—©æœŸåœæ­¢ã®ãƒ‘ãƒã‚¨ãƒ³ã‚¹
    
    # ãƒ‡ãƒ¼ã‚¿è¨­å®š
    num_workers: 4              # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
    val_split_ratio: 0.2        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²æ¯”ç‡
    
    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    model_name: "padim"         # padim, patchcore, fastflow
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼è¨­å®š
    optimizer: "adam"           # adam, sgd, adamw
    weight_decay: 1e-5          # é‡ã¿æ¸›è¡°
    
    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼
    lr_scheduler: "cosine"      # cosine, step, exponential
    lr_step_size: 30           # ã‚¹ãƒ†ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ç”¨
    lr_gamma: 0.1              # ã‚¹ãƒ†ãƒƒãƒ—ãƒ»æŒ‡æ•°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ç”¨
    
    # GPUè¨­å®š
    device: "auto"             # auto, cpu, cuda
    mixed_precision: false     # æ··åˆç²¾åº¦å­¦ç¿’
```

#### 2. **GUIè¨­å®š** (`training_app/gui/main_window.py`)

å®Ÿè¡Œæ™‚ã«GUIã§ä»¥ä¸‹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´å¯èƒ½ï¼š

- **ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—**: PaDiM, PatchCore, FastFlow
- **ã‚¨ãƒãƒƒã‚¯æ•°**: å­¦ç¿’ã®åå¾©å›æ•°
- **ãƒãƒƒãƒã‚µã‚¤ã‚º**: ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
- **å­¦ç¿’ç‡**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã®å¤§ãã•
- **ãƒ‡ãƒã‚¤ã‚¹**: auto, cpu, cuda
- **æ—©æœŸåœæ­¢**: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ãŒæ­¢ã¾ã£ãŸã‚‰å­¦ç¿’çµ‚äº†

#### 3. **ãƒ—ãƒ­ã‚°ãƒ©ãƒ è¨­å®š** (`training_manager.py`)

å†…éƒ¨çš„ã«ä½¿ç”¨ã•ã‚Œã‚‹è©³ç´°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼š

```python
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨­å®š
"train_batch_size": self.config.get('training.batch_size', 16)
"eval_batch_size": self.config.get('training.eval_batch_size', 16)  
"num_workers": self.config.get('training.num_workers', 4)
"val_split_ratio": self.config.get('training.val_split_ratio', 0.2)

# ã‚¨ãƒ³ã‚¸ãƒ³è¨­å®š
max_epochs=self.config.get('training.max_epochs', 10)
accelerator="gpu" if device == "cuda" else "cpu"
precision="16-mixed" if mixed_precision else "32"
```

### ğŸ”§ è¨­å®šæ–¹æ³•

#### **æ–¹æ³•1: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†**
```yaml
# config/config.yaml ã‚’ç›´æ¥ç·¨é›†
development:
  training:
    batch_size: 16        # ãƒ¡ãƒ¢ãƒªä¸è¶³ãªã‚‰å°ã•ã
    epochs: 50           # æ™‚é–“çŸ­ç¸®ãªã‚‰å°‘ãªã
    learning_rate: 0.01  # å­¦ç¿’ãŒé…ã„ãªã‚‰å¤§ãã
```

#### **æ–¹æ³•2: GUIã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èª¿æ•´**
1. å­¦ç¿’ã‚¢ãƒ—ãƒªã‚’èµ·å‹•
2. ã€Œãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€ã‚¿ãƒ–ã‚’é¸æŠ
3. ã€Œå­¦ç¿’è¨­å®šã€ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
4. ã€Œå­¦ç¿’é–‹å§‹ã€ã§å®Ÿè¡Œ

#### **æ–¹æ³•3: ç’°å¢ƒåˆ¥è¨­å®š**
- `development`: é–‹ç™ºãƒ»å®Ÿé¨“ç”¨ï¼ˆé«˜æ€§èƒ½è¨­å®šï¼‰
- `production`: æœ¬ç•ªç’°å¢ƒç”¨ï¼ˆå®‰å®šæ€§é‡è¦–ï¼‰
- `test`: ãƒ†ã‚¹ãƒˆç”¨ï¼ˆè»½é‡è¨­å®šï¼‰

### ğŸ›ï¸ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã®ã‚³ãƒ„

#### **ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å ´åˆ**
```yaml
batch_size: 8          # 32 â†’ 8ã«å‰Šæ¸›
num_workers: 2         # 4 â†’ 2ã«å‰Šæ¸›
```

#### **å­¦ç¿’é«˜é€ŸåŒ–**
```yaml
batch_size: 64         # å¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚º
num_workers: 8         # å¤šãã®ãƒ¯ãƒ¼ã‚«ãƒ¼
mixed_precision: true  # æ··åˆç²¾åº¦æœ‰åŠ¹
device: "cuda"         # GPUä½¿ç”¨
```

#### **é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«**
```yaml
epochs: 200            # é•·æ™‚é–“å­¦ç¿’
learning_rate: 0.0001  # å°ã•ãªå­¦ç¿’ç‡
early_stopping_patience: 20  # å¿è€å¼·ã
```

### ğŸ“Š æ¨å¥¨è¨­å®š

| ç”¨é€” | batch_size | epochs | learning_rate | device |
|------|------------|--------|---------------|--------|
| é–‹ç™ºãƒ»å®Ÿé¨“ | 16-32 | 50-100 | 0.001 | cuda |
| æœ¬ç•ªå“è³ª | 16-64 | 100-200 | 0.0005 | cuda |
| è»½é‡ãƒ†ã‚¹ãƒˆ | 8-16 | 10-20 | 0.01 | cpu |
| GPUæœ€é©åŒ– | 64-128 | 100+ | 0.001 | cuda |

### ğŸ” è¨­å®šã®ç¢ºèª

ç¾åœ¨ã®è¨­å®šã‚’ç¢ºèªï¼š
```python
from training_app.core.training_manager import TrainingManager
tm = TrainingManager()
print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {tm.config.get('training.batch_size')}")
print(f"ã‚¨ãƒãƒƒã‚¯æ•°: {tm.config.get('training.epochs')}")
print(f"å­¦ç¿’ç‡: {tm.config.get('training.learning_rate')}")
```

ã“ã‚Œã‚‰ã®è¨­å®šã«ã‚ˆã‚Šã€æ§˜ã€…ãªãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ç’°å¢ƒã‚„å­¦ç¿’è¦ä»¶ã«æŸ”è»Ÿã«å¯¾å¿œã§ãã¾ã™ã€‚